import os
import streamlit as st
from dotenv import load_dotenv
from modules.document_processor import load_all_documents
from modules.vector_store import prepare_vectorstore
from langchain.chains.question_answering import load_qa_chain
from langchain.agents import Tool, initialize_agent
from langchain.agents.agent_types import AgentType
from langchain_community.chat_models import ChatOllama
from langchain_openai import OpenAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ .env
load_dotenv()

# T·∫£i t√†i li·ªáu v√† t·∫°o vectorstore t·ª´ FAISS
@st.cache_resource(show_spinner="üîÑ ƒêang t·∫£i t√†i li·ªáu v√† t·∫°o vector...")
def load_docs_and_vectorstore():
    docs = load_all_documents("data/")
    vectorstore = prepare_vectorstore(docs)
    return docs, vectorstore

# C·∫•u h√¨nh LLM t·ª´ OpenAI (c√≥ th·ªÉ d√πng Azure)
def init_llm():
    # return ChatOllama(model="mistral") 
    return OpenAI(
    base_url="https://models.inference.ai.azure.com",
    api_key= "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",
    model="gpt-4o",
    temperature=0.1,
    )



# T·∫°o agent RAG v·ªõi c√°c c√¥ng c·ª• ri√™ng bi·ªát
def build_agent(llm, retriever, memory):
    qa_chain = load_qa_chain(llm=llm, chain_type="stuff")

    def retrieve_docs_fn(q):
        docs = retriever.get_relevant_documents(q)
        return "\n\n".join([doc.page_content for doc in docs])

    def answer_from_docs_fn(q):
        docs = retriever.get_relevant_documents(q)
        return qa_chain.run(input_documents=docs, question=q)
    
    def generic_csv_analysis_fn(query):
        import re

        match = re.search(r"trong file (\w+\.csv)", query)
        if not match:
            return "‚ùå Kh√¥ng t√¨m th·∫•y t√™n file CSV trong c√¢u h·ªèi."

        filename = match.group(1)

        # M·∫´u ƒëi·ªÅu ki·ªán: t√¨m ng∆∞·ªùi tr√™n 50 tu·ªïi
        def condition_fn(df):
            if "age" not in df.columns:
                return f"‚ùå File '{filename}' kh√¥ng c√≥ c·ªôt 'age'."
            count = df[df["age"] > 50].shape[0]
            return f"‚úÖ File '{filename}' c√≥ {count} ng∆∞·ªùi tr√™n 50 tu·ªïi."

        from modules.document_processor import analyze_csv_by_filename
        return analyze_csv_by_filename(filename, condition_fn)


    summarize_prompt = PromptTemplate(
        input_variables=["text"],
        template="T√≥m t·∫Øt n·ªôi dung sau m·ªôt c√°ch ng·∫Øn g·ªçn v√† logic:\n\n{text}\n\nT√≥m t·∫Øt:"
    )
    summarize_chain = LLMChain(llm=llm, prompt=summarize_prompt)

    def summarize_fn(q):
        docs = retriever.get_relevant_documents(q)
        combined_text = "\n\n".join([doc.page_content for doc in docs])
        return summarize_chain.run(text=combined_text)

    tools = [
        Tool(
            name="RetrieveDocuments",
            func=retrieve_docs_fn,
            description="Use this tool to retrieve relevant documents from the uploaded data. Always reply in ReAct format like: Thought: ... Action: RetrieveDocuments Action Input: your query"
        ),
        Tool(
            name="AnswerFromDocs",
            func=answer_from_docs_fn,
            description="Use this tool to answer questions using retrieved documents. Always reply in ReAct format like: Thought: ... Action: AnswerFromDocs Action Input: your question"
        ),
        Tool(
            name="SummarizeContent",
            func=summarize_fn,
            description="Use this tool to summarize documents relevant to the query. Always reply in ReAct format like: Thought: ... Action: SummarizeContent Action Input: your query"
        ),
        Tool(
            name="AnalyzeAnyCSV",
            func=generic_csv_analysis_fn,
            description="D√πng ƒë·ªÉ ph√¢n t√≠ch file CSV c·ª• th·ªÉ. V√≠ d·ª•: 'C√≥ bao nhi√™u ng∆∞·ªùi tr√™n 50 tu·ªïi trong file insurance.csv?'"
        )

    ]

    return initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=False,  # ‚úÖ T·∫Øt verbose ƒë·ªÉ kh√¥ng log Thought/Action
    handle_parsing_errors=True,
    return_intermediate_steps=False,  # ‚úÖ Ch·ªâ tr·∫£ Final Answer
    agent_kwargs={
        "prefix": (
            "B·∫°n l√† tr·ª£ l√Ω AI. N·∫øu ng∆∞·ªùi d√πng ch·ªâ ch√†o h·ªèi ('hi', 'hello', 'xin ch√†o'), "
            "b·∫°n s·∫Ω tr·∫£ l·ªùi th·∫≥ng m√† kh√¥ng c·∫ßn th·ª±c hi·ªán Action n√†o.\n\n"
            "N·∫øu c√¢u h·ªèi c·∫ßn d·ªØ li·ªáu, b·∫°n s·∫Ω d√πng Thought ‚Üí Action ‚Üí Observation."
        )
    }
)




# Giao di·ªán ng∆∞·ªùi d√πng

def main():
    st.set_page_config(page_title="Agentic RAG", page_icon="ü§ñ")
    st.title("üß† Agentic RAG Assistant")

    if "agent" not in st.session_state:
        docs, vectorstore = load_docs_and_vectorstore()
        llm = init_llm()
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="output"
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
        agent = build_agent(llm, retriever, memory)

        st.session_state.docs = docs
        st.session_state.vectorstore = vectorstore
        st.session_state.llm = llm
        st.session_state.memory = memory
        st.session_state.agent = agent
        st.session_state.conversation = []

        st.success("‚úÖ Agent ƒë√£ s·∫µn s√†ng!")

    # Form nh·∫≠p c√¢u h·ªèi
    query = st.text_input("üí¨ Nh·∫≠p c√¢u h·ªèi:")
    col1, col2 = st.columns([5, 1])
    with col2:
        if st.button("‚èπ D·ª´ng"):
            st.session_state.stop_generation = True

    # X·ª≠ l√Ω c√¢u h·ªèi
    if query:
        with st.spinner("ü§ñ ƒêang x·ª≠ l√Ω..."):
            if st.session_state.get("stop_generation"):
                st.warning("‚õî ƒê√£ d·ª´ng ph·∫£n h·ªìi.")
                st.session_state.stop_generation = False
                return
            try:
                st.session_state.conversation.append({"role": "user", "content": query})
                result = st.session_state.agent.invoke({"input": query})
                answer = result.get("output", "")  # Ch·ªâ l·∫•y Final Answer g·ªçn g√†ng
                st.session_state.conversation.append({"role": "ai", "content": answer})
            except Exception as e:
                st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {e}")
            st.session_state.stop_generation = False

    # Hi·ªÉn th·ªã h·ªôi tho·∫°i
    for msg in st.session_state.conversation[-10:]:
        icon = "üë§" if msg["role"] == "user" else "ü§ñ"
        st.markdown(f"**{icon}**: {msg['content']}")

if __name__ == "__main__":
    main()
